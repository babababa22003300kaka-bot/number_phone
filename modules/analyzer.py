#!/usr/bin/env python3
"""Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙØ­Ø³Ù‘Ù† (AsyncIO)"""

import re
import httpx
from bs4 import BeautifulSoup
from html import unescape
from typing import Dict, List, Optional, Tuple
from urllib.parse import urljoin, urlparse

class WebAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø°ÙƒÙŠ (Ù†Ø³Ø®Ø© AsyncIO)"""
    
    def __init__(
        self, 
        html_keywords: List[str],
        api_keywords: List[str],
        timeout: int = 10,
        max_size: int = 3145728,
        user_agent: str = None
    ):
        self.html_keywords = [k.lower() for k in html_keywords]
        self.api_keywords = [k.lower() for k in api_keywords]
        self.timeout = timeout
        self.max_size = max_size
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ AsyncClient
        self.client = httpx.AsyncClient(
            timeout=timeout,
            follow_redirects=True,
            limits=httpx.Limits(max_connections=200, max_keepalive_connections=50),
            headers={
                "User-Agent": user_agent or "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                "Accept-Language": "en-US,en;q=0.9,ar;q=0.8"
            },
            verify=False  # ØªØ¬Ø§Ù‡Ù„ Ø£Ø®Ø·Ø§Ø¡ SSL Ù„Ù„Ø³Ø±Ø¹Ø©
        )
    
    def detect_protection(self, response: httpx.Response, html: str) -> Tuple[bool, str]:
        """ÙƒØ´Ù Cloudflare/Captcha"""
        # Cloudflare
        if 'cf-ray' in response.headers or 'cloudflare' in html.lower():
            return True, "cloudflare"
        
        # Captcha
        captcha_indicators = ['recaptcha', 'hcaptcha', 'captcha', 'g-recaptcha']
        if any(ind in html.lower() for ind in captcha_indicators):
            return True, "captcha"
        
        return False, "clean"
    
    def analyze_inputs(self, soup: BeautifulSoup) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„"""
        phone_score = 0
        verify_score = 0
        evidence = []
        
        for inp in soup.find_all(["input", "textarea", "select"]):
            # Ø¬Ù…Ø¹ Ø§Ù„Ù€ attributes
            attrs_text = " ".join([
                str(inp.get(a, "")) 
                for a in ["id", "name", "class", "placeholder", "type", 
                         "inputmode", "autocomplete", "aria-label"]
            ]).lower()
            
            # Type=tel Ø£Ùˆ inputmode=tel
            if inp.get("type") == "tel" or inp.get("inputmode") == "tel":
                phone_score += 30
                evidence.append({
                    "type": "input_type_tel",
                    "confidence": "high",
                    "element": str(inp)[:200]
                })
            
            # Autocomplete
            if "tel" in inp.get("autocomplete", "").lower():
                phone_score += 20
            
            # HTML Keywords
            for kw in self.html_keywords:
                if kw in attrs_text:
                    if kw in ["phone", "mobile", "tel"]:
                        phone_score += 15
                    elif kw in ["verify", "otp", "code"]:
                        verify_score += 15
                    evidence.append({
                        "type": "input_keyword",
                        "keyword": kw,
                        "element": str(inp)[:200]
                    })
            
            # Pattern Ù„Ù„Ù€ phone
            pattern = inp.get("pattern", "")
            if pattern and re.search(r'[\d\+\-\(\)]{6,}', pattern):
                phone_score += 10
        
        return {
            "phone_score": min(phone_score, 100),
            "verify_score": min(verify_score, 100),
            "evidence": evidence[:10]  # Ø£ÙˆÙ„ 10 ÙÙ‚Ø·
        }
    
    def analyze_text(self, soup: BeautifulSoup) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ù€ labels"""
        phone_score = 0
        verify_score = 0
        evidence = []
        
        for tag in soup.find_all(["label", "button", "a", "h1", "h2", "h3", "span"]):
            text = unescape(" ".join(tag.stripped_strings)).lower()
            if not text or len(text) > 200:
                continue
            
            for kw in self.html_keywords:
                if kw in text:
                    if kw in ["phone", "mobile", "signup", "register"]:
                        phone_score += 5
                    elif kw in ["verify", "otp", "send"]:
                        verify_score += 10
                    evidence.append({
                        "type": "text_keyword",
                        "keyword": kw,
                        "snippet": text[:100]
                    })
        
        return {
            "phone_score": min(phone_score, 50),
            "verify_score": min(verify_score, 50),
            "evidence": evidence[:10]
        }
    
    def analyze_api(self, soup: BeautifulSoup, html: str) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù€ API endpoints"""
        verify_score = 0
        endpoints = []
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ scripts
        scripts = soup.find_all("script")
        script_text = " ".join([s.get_text() for s in scripts if s.string])
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† URLs
        url_pattern = r'(?:https?://[^\s"\'\)<>]+|/api/[^\s"\'\)<>]+|/v\d+/[^\s"\'\)<>]+)'
        found_urls = re.findall(url_pattern, html + script_text)
        
        for url in found_urls:
            url_lower = url.lower()
            for kw in self.api_keywords:
                if kw in url_lower:
                    verify_score += 20
                    endpoints.append({
                        "url": url,
                        "keyword": kw,
                        "confidence": "high"
                    })
                    break
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† function names
        api_patterns = [
            r'(send(?:Otp|OTP|Sms|SMS|Code|Verification))',
            r'(verify(?:Otp|OTP|Code|Phone|SMS))',
            r'(check(?:Otp|OTP|Phone))'
        ]
        
        for pattern in api_patterns:
            matches = re.findall(pattern, script_text, re.IGNORECASE)
            for match in matches[:5]:
                verify_score += 15
                endpoints.append({
                    "function": match,
                    "confidence": "medium"
                })
        
        return {
            "verify_score": min(verify_score, 100),
            "endpoints": endpoints[:10]
        }
    
    def calculate_confidence(self, results: Dict) -> int:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©"""
        phone_score = results["phone_score"]
        verify_score = results["verify_score"]
        
        # Ù„Ùˆ ÙÙŠ phone Ù‚ÙˆÙŠ + verify Ù‚ÙˆÙŠ
        if phone_score >= 40 and verify_score >= 40:
            return min(phone_score + verify_score, 100)
        
        # Ù„Ùˆ ÙÙŠ phone Ù‚ÙˆÙŠ Ø¨Ø³
        elif phone_score >= 50:
            return phone_score + (verify_score // 2)
        
        # Ù„Ùˆ ÙÙŠ verify Ù‚ÙˆÙŠ Ø¨Ø³
        elif verify_score >= 50:
            return verify_score + (phone_score // 2)
        
        # Ø¶Ø¹ÙŠÙ
        else:
            return (phone_score + verify_score) // 2

    async def check_paths(self, base_url: str, paths: List[str]) -> List[Dict]:
        """ÙØ­Øµ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ© (Path Fuzzing)"""
        found_paths = []
        
        for path in paths:
            full_url = urljoin(base_url, path)
            try:
                # Ø·Ø¨Ø§Ø¹Ø© Ù…Ø³Ø§Ø± Ø§Ù„ÙØ­Øµ (Verbose)
                print(f"ğŸ” [PATH] Checking {full_url} ...", end="\r")
                
                response = await self.client.get(full_url)
                
                # Ù„Ùˆ Ø§Ù„ØµÙØ­Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© (200 OK)
                if response.status_code == 200:
                    html = response.text
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ Ù„Ù„ØµÙØ­Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ©
                    soup = BeautifulSoup(html, "lxml")
                    inputs = self.analyze_inputs(soup)
                    text = self.analyze_text(soup)
                    
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³ÙƒÙˆØ± Ù„Ù„ØµÙØ­Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ©
                    sub_score = inputs["phone_score"] + text["phone_score"] + inputs["verify_score"]
                    
                    if sub_score > 20:  # Ù„Ùˆ ÙÙŠÙ‡Ø§ Ø£ÙŠ Ø±ÙŠØ­Ø© phone/verify
                        found_paths.append({
                            "url": full_url,
                            "score": sub_score,
                            "title": soup.title.string.strip() if soup.title else "No Title"
                        })
            except:
                continue
                
        return found_paths

    async def analyze(self, url: str, scan_paths: List[str] = None) -> Optional[Dict]:
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ (Async)"""
        try:
            # Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
            response = await self.client.get(url)
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¬Ù…
            if len(response.content) > self.max_size:
                return {"url": url, "status": "oversize", "confidence": 0}
            
            html = response.text
            
            # ÙƒØ´Ù Ø§Ù„Ø­Ù…Ø§ÙŠØ©
            is_protected, protection_type = self.detect_protection(response, html)
            if is_protected:
                return {
                    "url": url,
                    "status": "protected",
                    "protection": protection_type,
                    "confidence": 0
                }
            
            # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
            soup = BeautifulSoup(html, "lxml")
            
            inputs = self.analyze_inputs(soup)
            text = self.analyze_text(soup)
            api = self.analyze_api(soup, html)
            
            # Ø§Ù„Ø¯Ø±Ø¬Ø§Øª
            phone_score = inputs["phone_score"] + text["phone_score"]
            verify_score = inputs["verify_score"] + text["verify_score"] + api["verify_score"]
            
            results = {
                "phone_score": min(phone_score, 100),
                "verify_score": min(verify_score, 100)
            }
            
            confidence = self.calculate_confidence(results)
            
            # ğŸš€ Path Fuzzing (Ù„Ùˆ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø´ØºØ§Ù„ Ø£Ùˆ Ø·Ù„Ø¨Ù†Ø§ ÙØ­Øµ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª)
            valid_paths = []
            if scan_paths and (confidence > 10 or response.status_code == 200):
                valid_paths = await self.check_paths(url, scan_paths)
                
                # Ù„Ùˆ Ù„Ù‚ÙŠÙ†Ø§ Ù…Ø³Ø§Ø± ØªØ³Ø¬ÙŠÙ„ Ù‚ÙˆÙŠØŒ Ù†Ø¹Ù„ÙŠ Ø§Ù„Ø«Ù‚Ø©
                if valid_paths:
                    confidence = max(confidence, 80)
                    results["phone_score"] = max(results["phone_score"], 80)
            
            return {
                "url": url,
                "status": "analyzed",
                "http_status": response.status_code,
                "confidence": confidence,
                "phone_score": results["phone_score"],
                "verify_score": results["verify_score"],
                "evidence": {
                    "inputs": inputs["evidence"][:5],
                    "text": text["evidence"][:5],
                    "api": api["endpoints"][:5],
                    "paths": valid_paths  # Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©
                }
            }
        
        except httpx.TimeoutException:
            return {"url": url, "status": "timeout", "confidence": 0}
        except httpx.ConnectError:
            return {"url": url, "status": "connection_error", "confidence": 0}
        except Exception as e:
            return {"url": url, "status": "error", "error": str(e), "confidence": 0}
    
    async def close(self):
        """Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù€ client"""
        await self.client.aclose()