#!/usr/bin/env python3
"""
Ø¨ÙˆØª Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¢Ù„ÙŠ Ø¹Ù† Ù…ØµØ§Ø¯Ø± OTP
Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 2.5 (Phase 2: Performance Optimized + Async Database)
"""

import asyncio
import json
import os
import sys
import time
import io
from pathlib import Path
from dotenv import load_dotenv

from modules.analyzer import WebAnalyzer
from modules.database import HashDB
from modules.telegram_bot import TelegramNotifier
from modules import dork_scanner
from modules import generator
from typing import Dict, List, Optional

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”§ ØªÙ‡ÙŠØ¦Ø© Ø·Ø¨Ø§Ø¹Ø© Unicode Ø¹Ù„Ù‰ Windows
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”§ ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def load_config() -> Dict:
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"""
    config_path = Path("config/settings.json")
    if not config_path.exists():
        print("âŒ Ù…Ù„Ù settings.json Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯!")
        sys.exit(1)
    
    with open(config_path, "r", encoding="utf-8") as f:
        return json.load(f)

def load_file_lines(filepath: str) -> List[str]:
    """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ù†ØµÙŠ"""
    path = Path(filepath)
    if not path.exists():
        if "words" in filepath:
            return ["cloud", "net", "app", "tech", "web", "data", "fast", "pro", "smart", "link"]
        print(f"âš ï¸ Ø§Ù„Ù…Ù„Ù {filepath} Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯!")
        return []
    
    with open(path, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]

def load_serpapi_key() -> Optional[str]:
    """
    ØªØ­Ù…ÙŠÙ„ SerpAPI key Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
    ÙŠØ¬Ø±Ø¨ SERP_API_KEY_1 Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø«Ù… SERP_API_KEY_2
    """
    # Try first key
    key1 = os.getenv("SERP_API_KEY_1")
    if key1 and 'YOUR_' not in key1.upper():
        return key1
    
    # Try second key
    key2 = os.getenv("SERP_API_KEY_2")
    if key2 and 'YOUR_' not in key2.upper():
        return key2
    
    return None

def sanitize_url(url: str) -> Optional[str]:
    """
    ØªÙ†Ø¸ÙŠÙ ÙˆÙØ­Øµ URL Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
    
    Args:
        url: Ø§Ù„Ø±Ø§Ø¨Ø·
        
    Returns:
        str: Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†Ø¸Ù Ø£Ùˆ None Ø¥Ø°Ø§ ÙƒØ§Ù† ØºÙŠØ± Ø¢Ù…Ù†
    """
    from urllib.parse import urlparse
    
    try:
        # Parse URL
        parsed = urlparse(url)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„
        if parsed.scheme not in ['http', 'https']:
            return None
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ hostname
        if not parsed.netloc:
            return None
        
        # ØªÙ†Ø¸ÙŠÙ Ù…Ù† Ø£Ø­Ø±Ù Ø®Ø·ÙŠØ±Ø©
        dangerous_chars = ['<', '>', ';', '&', '|', '`', '$']
        if any(char in url for char in dangerous_chars):
            return None
        
        return url
        
    except Exception:
        return None

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸ”§ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Async)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

async def process_url(url: str, analyzer: WebAnalyzer, hash_db: HashDB, threshold: int, scan_paths: List[str]) -> Dict:
    """ÙØ­Øµ Ø±Ø§Ø¨Ø· ÙˆØ§Ø­Ø¯ (Async with DB optimization)"""
    if hash_db:
        is_duplicate = await hash_db.is_checked(url)  # â† Async!
        if is_duplicate:
            return {"url": url, "status": "duplicate", "confidence": 0}
    
    result = await analyzer.analyze(url, scan_paths=scan_paths)
    
    if hash_db and result:
        await hash_db.mark_checked(  # â† Async!
            url,
            result.get("status", "unknown"),
            confidence=result.get("confidence", 0),
            method=result.get("method", "httpx"),
            phone_score=result.get("phone_score", 0),
            verify_score=result.get("verify_score", 0),
            signatures=result.get("evidence", {}).get("signatures", [])
        )
    
    if result and result.get("confidence", 0) >= threshold:
        return result
    
    return result

async def worker(queue: asyncio.Queue, analyzer: WebAnalyzer, hash_db: HashDB, threshold: int, telegram: TelegramNotifier, stats: Dict, scan_paths: List[str]):
    """Ø¹Ø§Ù…Ù„ (Worker) Ø¨ÙŠØ³Ø­Ø¨ Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„Ø·Ø§Ø¨ÙˆØ± ÙˆÙŠÙØ­ØµÙ‡Ø§"""
    while True:
        url = await queue.get()
        try:
            # ØªÙ†Ø¸ÙŠÙ URL Ø£ÙˆÙ„Ø§Ù‹
            clean_url = sanitize_url(url)
            if not clean_url:
                print(f"âš ï¸ [SKIP] {url} (Invalid URL)")
                continue
            
            print(f"ğŸ” [CHECK] {clean_url} ...", end="\r")
            
            result = await process_url(clean_url, analyzer, hash_db, threshold, scan_paths)
            
            stats['checked'] += 1
            
            if result:
                confidence = result.get("confidence", 0)
                status = result.get("status", "unknown")
                
                if confidence >= threshold:
                    stats['found'] += 1
                    sigs = result.get("evidence", {}).get("signatures", [])
                    sig_text = f" [Sigs: {','.join(sigs)}]" if sigs else ""
                    print(f"âœ… [FOUND] {url} (Conf: {confidence}%){sig_text} - Phone: {result.get('phone_score')}% | Verify: {result.get('verify_score')}%")
                    
                    if telegram:
                        await telegram.send_result(result)
                
                elif status == "excluded":
                    print(f"ğŸš« [EXCL] {url} ({result.get('reason')})")
                
                elif status == "protected":
                    print(f"ğŸ›¡ï¸ [PROT] {url} ({result.get('protection')})")
                
                elif status == "timeout":
                    print(f"â±ï¸ [TIME] {url} (Timeout)")
                
                elif status == "connection_error":
                    print(f"ğŸ”Œ [CONN] {url} (Connection Error)")
                
                elif status == "duplicate":
                    print(f"ğŸ”„ [DUPL] {url} (Already Checked)")
                
                else:
                    print(f"âŒ [FAIL] {url} (Conf: {confidence}%)")
            else:
                print(f"âš ï¸ [ERR ] {url} (No Result)")

        except Exception as e:
            print(f"ğŸ’¥ [ERR ] {url}: {str(e)}")
        
        finally:
            queue.task_done()

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ğŸš€ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

async def main_async():
    print("""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ Ø¨ÙˆØª Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¢Ù„ÙŠ - v2.5 (Phase 2)
âœ¨ Performance Optimized + Async DB
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    """)
    
    # 1. Ø§Ù„ØªØ­Ù…ÙŠÙ„
    print("ğŸ“¦ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª...")
    
    # ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ù† Ù…Ù„Ù .env
    load_dotenv()
    
    config = load_config()
    domains = load_file_lines("config/domains.txt")
    html_keywords = load_file_lines("config/html_keywords.txt")
    api_keywords = load_file_lines("config/api_keywords.txt")
    exclude_keywords = load_file_lines("config/exclude.txt")
    words = load_file_lines("config/words.txt")
    names = load_file_lines("config/names.txt")
    locations = load_file_lines("config/locations.txt")
    
    if not domains:
        print("âŒ Ù„Ø§Ø²Ù… ØªØ¶ÙŠÙ Ø¯ÙˆÙ…ÙŠÙ†Ø§Øª ÙÙŠ domains.txt!")
        sys.exit(1)
    
    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„: {len(domains)} Ø¯ÙˆÙ…ÙŠÙ† | {len(html_keywords)} HTML KW | {len(api_keywords)} API KW")
    print(f"âœ… Ø§Ù„Ù‚ÙˆØ§Ø¦Ù…: {len(words)} ÙƒÙ„Ù…Ø§Øª | {len(names)} Ø£Ø³Ù…Ø§Ø¡ | {len(locations)} Ù…ÙˆØ§Ù‚Ø¹ | {len(exclude_keywords)} Ø§Ø³ØªØ¨Ø¹Ø§Ø¯")
    print(f"âš¡ Ø§Ù„Ø³Ø±Ø¹Ø©: {config['threads']} Workers (AsyncIO)")
    
    # 2. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯
    hybrid_config = config.get('hybrid_system', {})
    
    analyzer = WebAnalyzer(
        html_keywords=html_keywords,
        api_keywords=api_keywords,
        exclude_keywords=exclude_keywords,
        timeout=config['timeout'],
        max_size=config['max_response_size'],
        user_agent=config['user_agent'],
        browser_service_url=hybrid_config.get('browser_service_url') if hybrid_config.get('enabled') else None,
        fallback_threshold=hybrid_config.get('fallback_confidence_threshold', 20)
    )
    
    hash_db = None
    if config.get('use_hash_db', True):
        hash_db = HashDB(config.get('hash_db_file', 'checked_urls.db'))
        await hash_db.initialize()  # â† Async initialization!
        print("ğŸ’¾ Database: Initialized (Async + aiosqlite)")
    
    telegram = None
    # Ù‚Ø±Ø§Ø¡Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
    bot_token = os.getenv("TELEGRAM_BOT_TOKEN")
    chat_id = os.getenv("TELEGRAM_CHAT_ID")
    
    if config.get('telegram', {}).get('enabled', False) and bot_token and chat_id:
        telegram = TelegramNotifier(
            bot_token=bot_token,
            chat_id=chat_id
        )
        print("ğŸ“¡ Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…: Ù…ØªØµÙ„ (Ù…Ù† Ù…Ù„Ù .env Ø§Ù„Ø¢Ù…Ù†)")
    else:
        if config.get('telegram', {}).get('enabled', False):
            print("âš ï¸ Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…: Ù…Ø¹Ø·Ù„ (ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ù„Ù .env)")
    
    # 3. ØªØ´ØºÙŠÙ„ Ø§Ù„Ù€ Workers
    queue = asyncio.Queue()
    stats = {'checked': 0, 'found': 0}
    scan_paths = config.get('scan_paths', [])
    
    workers = [
        asyncio.create_task(worker(queue, analyzer, hash_db, config['confidence_threshold'], telegram, stats, scan_paths))
        for _ in range(config['threads'])
    ]
    
    # 4. Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ØµØ§Ø¯Ø±
    dorking_config = config.get('dorking', {})
    if dorking_config.get('enabled'):
        print(f"ğŸ” ØªÙØ¹ÙŠÙ„ Google Dorking (Mode: {dorking_config.get('scanner_mode', 'hybrid')})")
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù€ dorks Ù…Ù† Ø§Ù„Ù…Ù„Ù
        dorks_file = dorking_config.get('dorks_file', 'config/dorks.txt')
        dorks = dork_scanner.load_dorks(dorks_file)
        
        # Ù‚Ø±Ø§Ø¡Ø© API key Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© (Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ø§Ù‹)
        api_key = load_serpapi_key()
        
        if dorks and api_key:
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(dorks)} Dorks")
            try:
                dork_urls = await dork_scanner.fetch_dork_urls(  # â† Async!
                    dorks=dorks,
                    api_key=api_key,
                    count=20,
                    num_results_per_dork=10
                )
                
                print(f"âœ… Ù†ØªØ§Ø¦Ø¬ Dorking: {len(dork_urls)} Ø±Ø§Ø¨Ø·")
                
                for url in dork_urls:
                    await queue.put(url)
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Dorking: {e}")
        else:
            print("âš ï¸ Dorking: ØºÙŠØ± Ù…ÙØ¹Ù„ (ØªØ­Ù‚Ù‚ Ù…Ù† .env)")
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©
    total_urls = 0
    
    ratio = dorking_config.get('ratio', 0.5) if dorking_config.get('enabled') else 1.0
    generated_count = int(500 * ratio) if dorking_config.get('enabled') else 500
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
    generated_urls = generator.generate_urls(
        count=generated_count,
        domains=domains,
        word_list=words,
        names=names,
        locations=locations
    )
    
    for url in generated_urls:
        await queue.put(url)
        total_urls += 1
    
    print(f"ğŸŒ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·: {total_urls + queue.qsize()}")
    
    # 5. Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù†ØªÙ‡Ø§Ø¡ ÙƒÙ„ Ø§Ù„Ù…Ù‡Ø§Ù…
    try:
        await queue.join()
    except KeyboardInterrupt:
        print("\nâ¸ï¸ ØªÙˆÙ‚Ù ÙŠØ¯ÙˆÙŠ...")
    finally:
        await analyzer.close()
        
        print(f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ ØªÙ… ÙØ­Øµ: {stats['checked']} Ù…ÙˆÙ‚Ø¹
â€¢ Ù…ÙˆØ§Ù‚Ø¹ Ù…Ø­ØªÙ…Ù„Ø©: {stats['found']}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        """)

def main():
    try:
        if sys.platform == 'win32':
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        asyncio.run(main_async())
    except KeyboardInterrupt:
        pass

if __name__ == "__main__":
    main()